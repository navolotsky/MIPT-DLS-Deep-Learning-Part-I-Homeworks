Репозиторий содержит прорешанные домашние задания по первой части курса по **Deep Learning** от [Школы глубокого обучения](https://www.dlschool.org/) МФТИ.
Работы выполнены мной в рамках прохождения [потока Advanced](https://www.dlschool.org/pro-track) этого курса (запуск осени 2020).
Работы сдавались через [Stepik](https://stepik.org/course/82177) и проверялись преподавателями курса.

Каждая папка представляет собой отдельное домашнее задание. Папки пронумерованы в порядке выдачи заданий.
В папках содержится:
* *task* — файл с описанием работы со Stepik
* *template* — папка/файл домашней работы в том виде, как она была задана
* *solution* — папка/файл прорешанной работы в том виде, как она была залиты на Stepik


## Список работ:

### Простенькие

1. **Основы машинного обучения**
    
    **Проделанная работа:** обучен простейший классификатор (метод K Nearest Neighbors) на табличных данных c применением Grid Search с помощью средств библиотек pandas и sklearn.
    
    **Оценка преподавателя:** 10/10


2. **Линейные модели и методы оптимизации**
    
    Реализованы функция градиентного спуска для конкретной заданной функции f, генератор батчей, класс для логистической регрессии с регуляризацией (l1 и l2). Класс протестирован обучением на сгенерированных данных и обучением на MNIST с применением кросс-валидации.
    
    12/12


3. **Решение ML-задачи и Kaggle**

    Исследованы табличные данные (использованы pandas, matplotlib). Применена линейная модель: реализован Pipeline для предобработки данных (нормализация числовых и кодирование категориальных признаков) для предотвращения утечки данных в процессе кросс-валидации; используя данный Pipeline и поиск по сетке (GridSearhCV) обучена логистическая регрессия из sklearn. Применён градиентный бустинг: обучен классификатор из catboost также с использованием Grid Search. Сделана посылка на Kaggle.

    15/15


4. **Свёрточные и полносвязные нейросети**

    Реализованы класс для логистической регрессии и цикл обучения на PyTorch. Сравнены несколько функций активации обучением простейшей трёхслойной нейронной сети на MNIST. Сравнены вручную заданные ядра свёрток. Обучена LeNet на MNIST.

    12/12


### Сложнее и объёмнее

5. **Классификация Симпсонов**

    Реализованы класс датасета для загрузки изображений, цикл обучения, чекпоинтинг, визуализация, простейшая аугментация данных, несколько простых свёрточных нейросетей (использованы Max pooling, Batch normalization, Dropout). Перебраны различные варианты сетей и гиперпараметров для достижения максимальной точности классификации. Сделан сабмит на Кагл. Попробовано несколько способов Fine tuning'а предобученной ResNet18. Попробовано применение Karpathy Constant.

    15/15


6. **Сегментация изображений**

    Реализованы архитектура SegNet и функции потерь Binary cross entropy loss, Dice loss, Focal loss (по описанию из текста домашнего задания и частично по соответствующим papers). Прочитана [paper](https://arxiv.org/abs/1910.08711) и реализована Correlation Maximized Structural Similarity Loss for Semantic Segmentation. Обучена SegNet с использованием перечисленных лоссов. Реализована Unet и обучена с bce loss. Проведено сравнение качества сегментации (по метрике IoU), производимой обученными моделями.

    17/20


7. **GAN и Style Transfer**

    Выбран CycleGAN. Собран непарный датасет изображений бананов и огурцов. Прочитана [paper](https://arxiv.org/abs/1703.10593) Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks и имплементирован from scratch (не без недостатков) описанный там метод. Модель обучена на собранном датасете. Выполнен инференс: попытка превратить бананы в огурцы и наоборот.

    10/10
    
    Решение представлено в двух вариантах:
    * папка *solution*, содержащая только код имплементации метода
    * файл *solution.ipynb*, содержащий весь код из папки *solution*, но с дополнительным описанием проведённой работы и трудностей, возникших в её процессе

    Также датасет, ноутбук, код и результаты инференса на тесте доступны на [Google Диске](https://drive.google.com/drive/folders/1saKH6_K5nPEt3nDssyZbkc6mSe71Avsb?usp=sharing).

    **NB:** В папке *solution* представлена наиболее актуальная версия кода с найденными и/или исправленными ошибками. В ноутбуке, на гугл-диске содержится устаревший код, результаты инференса на гугл-диске также приведены с запуска на устаревшей версии кода.

## Итоговый проект
Из списка предложенных вариантов выбран и реализован telegram-бот (см. [репозиторий](https://github.com/navolotsky/neural-style-transfer-telegram-bot)), осуществляющий нейронный перенос стиля изображений.

10/10


## Сертификат
**Условия выдачи:** см. [сообщение](https://t.me/deep_learning_school_news/61) в официальном телеграм-канале Школы.

**Результат:** 101/104 баллов набрано, финальный проект оценён на 10/10 — получен диплом I степени №202111000024031891 (см. файл *certificate.pdf*)